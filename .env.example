# Supabase Configuration
NEXT_PUBLIC_SUPABASE_URL=https://your-project.supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=your-anon-key-here
SUPABASE_SERVICE_ROLE_KEY=your-service-role-key-here

# App Configuration
APP_URL=http://localhost:3000
NODE_ENV=development

# Storage
ARTIFACTS_BUCKET=artifacts

# LLM Configuration (choose one or configure multiple)
LLM_PROVIDER=openai
# Options: openai, anthropic, ollama

# OpenAI
OPENAI_API_KEY=your-openai-key-here
OPENAI_MODEL=gpt-4o-mini
# For local Ollama, use: http://localhost:11434/v1
OPENAI_BASE_URL=

# Anthropic Claude
ANTHROPIC_API_KEY=your-anthropic-key-here
ANTHROPIC_MODEL=claude-sonnet-4-5

# Ollama (local)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1

# GitHub App Configuration
GITHUB_APP_ID=
GITHUB_APP_PRIVATE_KEY_B64=
GITHUB_INSTALLATION_ID=

# Runner Service Configuration
RUNNER_CONCURRENCY=3
RUNNER_POLL_INTERVAL_MS=3000
PLAYWRIGHT_HEADLESS=true
APP_BASE_URL_DEFAULT=http://host.docker.internal:3000